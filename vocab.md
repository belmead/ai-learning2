### Artificial General Intelligence (AGI)

### Artificial Narrow Intelligence (ANI)

### Convolution
The idea is similar to the algorithms that look at small-scale features in images first (edges and textures, for example)m, then zoom out to look at the big picture. (Shane, pg. 52)

### Deepfakes
[Allowing] people to swap one person's head and/or body for another, even in video. (Shane, pg. 35)

### Deep Neural Network
A (very) simplified model of our cerebrel cortex, composed of stacks of layers of artificial neurons. (Geron, pg. xv)

### Long Short-Term Memory (LSTM)
It also had a tiny bit of long-term memory where it could keep track of information for longer than that sixty five-character window, but that amount of memory was too tiny to store an entire ingredient list. In machine learning terms, that makes this algorithm a Long-Short Term Memory (LSTM) neural network rather than a plan RNN. (Shane, pg. 51)

### Machine Learning
[A] machine learning algorithm figures out the rules for itself via trial and error, gauging its success on goals the programmer has specified. As the AI tries to reach this goal, it can discover rules and correlations that the programmer didn't even know existed. (Shane, pg. 9)
The science (and art) of programming computers so they can learn from data. (Geron, pg. 4)
[The] field of study that gives computers the ability to learn without being explicitly programmed. (Arthur Samuel, 1959, via Geron, pg. 5) 
A computer program is said to learn from experience *E* with respect to some task *T* and some performance measure *P*, if its performance on *T*, as measured by *P*, improves with experience *E.* (Tom Mitchell, 1997, via Gero, pg. 5)

> "In this case, the task *T* is to flag spam for new emails, the experience *E* is the training data, and the performance measure *P* needs to be defined; for example, you can use the ratio of correctly classified emails.
> 
> Geron, pg. 4

### Model
The part of a machine learning system that learns and makes predictions. (Geron, pg. 4)

### Pseudo-AI
An approach wherein programs start out as AI-powered but switch control over to humans if things get tough. (Shane, pg. 20)

### Recurrent Neural Network (RNN)
Many text-enerating AIs can only keep track of a few workds at a time. (Shane, pg. 50)

### Rules-based learning
You create a list of commands, or rules, in a language the computer can understand, and the computer does exactly what you say. To solve a problem with a rules-based program, you have to know every step required to complete the program's task and how to describe each one of those steps. (Shane, pg. 9)

### Training Set
Examples the [machine learning] systems use to learn. (Geron, pg. 4)

### Training Instance (or Training Sample) 
Each training example [in a training set]. (Geron, pg. 4)

### Transfer Learning
[Starting] with an AI that's already partway to it's goal. (Shane, pg. 47)
